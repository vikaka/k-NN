{
    "contents" : "---\ntitle: \"Untitled\"\nauthor: \"Vishesh Kakarala\"\ndate: \"February 29, 2016\"\noutput: html_document\n---\n\n\n# Question 2\n\n\n```{r}\nlibrary('dplyr')\nlibrary('class')\n\nglass <- read.csv(\"~/Homework 2/glass.data\", header=FALSE)\nhead(glass)\nstr(glass)\ncolnames(glass) <- c(\"Id Number\",\"RI\",\"Na\",\"Mg\",\"Al\",\"Si\",\"K\",\"Ca\",\"Ba\",\"Fe\",\"Type of glass\")\n```\n## Question A\n\n```{r}\n# for loop to creat data frame column \"bi\"\n\nfor (i in 1:214)\n{\n  if(glass$'Type of glass'[i] <5)\n    {\n      glass$bi[i] <- 0\n    }\n  else\n    {\n    glass$bi[i] <- 1\n    }\n  i= i+1\n  \n}\n```\n\n## Question B\n```{r}\n\nfeatures <- glass[,-1]\nfeatures <- features[,-11]\nfeatures <- features[,-10]\n# to create the feature matrix the identifier,class type and \"bi\"\" columns are dropped\n\nfea <- data.frame(features)\n# y is the response vector\n\ny <- data.frame(glass$bi)\n```\n\n## Question C\n\ntraining - 80% \ntesting - 30%\nwe need a larger training data set for better model fit  \n\n```{r}\n#sample is taken from the original data and the corresponding respone variables are also split\ntrain_fea <- sample_frac(fea,0.8)\ntrain_y <- data.matrix(y[as.numeric(rownames(train_fea)),])\n\ntrain_values <- as.numeric(rownames(train_fea))\n\ntest_fea <- fea[-train_values,]\ntest_y <- data.matrix(y[as.numeric(rownames(test_fea)),])\n\n\ntrain_fea <- data.matrix(train_fea)\n\ntest_fea <- data.matrix(test_fea)\n\n#the training and test data is stored in matrix form\n```\n\n## Question D\n```{r}\n# From the class package, we use knn.cv to validate the exisitng response variables \n# kNN of order 5 is used\n\nfit_knn <- knn.cv(train_fea,train_y,k= 5)\n\n# the output is used as the new response varible and is used to predict test values\n```\n\n## Question E\n\n```{r}\n# Using the testing set and the training data predictions are made \n\ncheck_test <-data.frame(knn(train_fea,test_fea,fit_knn, k= 5))\ncheck_test$a <- test_y\n\ncolnames(check_test) <- c(\"Model output\",\"original data\")\n\n\ncheck_test$`Model output`<-data.frame(check_test$`Model output`)\n\nfor (i in 1:43)\n{\n  if(check_test$`Model output`[i,] == check_test$`original data`[i,])\n  {\n    check_test$accuracy[i] <- 1\n  }\n  else\n  {\n    check_test$accuracy[i] <- 0\n  }\n  i= i+1\n  \n}\n```\n# accuracy of the kNN model of order 5 is \n```{r}\n\n(sum(check_test$accuracy)/43)*100\n\n```\n\n## Question F\n\n```{r}\n\n#to compute the accuracy value for various levels of kNN\n# we must first initialise a storage data frame\n\naccuracy_test <- data.frame(5:25)\n\n\nfor(j in 1:20)\n{\n  check_test <-data.frame(knn(train_fea,test_fea,fit_knn, k= j+4))\n  check_test$a <- test_y\n\n  colnames(check_test) <- c(\"Model output\",\"original data\")\n\n  check_test$`Model output`<-data.frame(check_test$`Model output`)\n\n  for (i in 1:43)\n    {\n      if(check_test$`Model output`[i,] == check_test$`original data`[i,])\n        {\n          check_test$accuracy[i] <- 1\n        }\n      else\n        {\n          check_test$accuracy[i] <- 0\n        }\n    i= i+1\n  \n    }\n\n  accuracy_test$k_value[j] <- j+4\n  accuracy_test$Accuracy[j] <- sum(check_test$accuracy)/43\n  \n\n}\naccuracy_test <- accuracy_test[-1] \naccuracy_test <- accuracy_test[-21,] \n\n# the data frame accuracy_test contains the accuracy values for a reasonable range of K values\n```\n\n## Question G\n\n```{r}\nplot(accuracy_test$k_value,accuracy_test$Accuracy, type = \"l\")\n```\n\nOptimal value for k is 12 or 14  \n\n## Question H\n\nBy analysing the test class we can calculate the testing accuracy\n```{r}\ntable(test_y)\n```\nHere we can see that out of the 43 values there are 36 0's and 7 1's, hence to calculate null accuracy we get.  \n\nThus null accuracy is at \n```{r}\n(as.vector(table(test_y))[1])/43*100\n```\n\n\n#Bonus Points\n\n# To determine which predictors are good, we can use linear modelling to determine their significance\n```{r}\nlm_multiple <- lm(glass$bi~glass$RI +glass$Na +glass$Mg+glass$Al+glass$Si+glass$K+glass$Ca+glass$Ba+glass$Fe+glass$`Type of glass`)\n\nsummary(lm_multiple)\n```\n# from the analysis of the summary we find that the variables Na, Al, SI and K have significant influence on the response vector\n\n```{r}\n\nfeatures <- glass[,-1]\nfeatures <- features[,-11]\nfeatures <- features[,-10]\nfeatures <- features[,-1]\nfeatures <- features[,-2]\nfeatures <- features[,-5]\nfeatures <- features[,-5]\nfeatures <- features[,-5]\n\ncolnames(features)\n# only the significant varibales are used in the feature matrix\n\nfea_sig <- data.frame(features)\n# y is the response vector\n\ny_sig <- data.frame(glass$bi)\n```\n\n#### The rest of the process is followed as above\n\ntraining - 80% \ntesting - 30%\nwe need a larger training data set for better model fit  \n\n```{r}\n#sample is taken from the original data and the corresponding respone variables are also split\nset.seed(300)\n\ntrain_fea_sig <- sample_frac(fea_sig,0.8)\ntrain_y_sig <- data.matrix(y[as.numeric(rownames(train_fea_sig)),])\n\ntrain_values_sig <- as.numeric(rownames(train_fea_sig))\n\ntest_fea_sig <- fea_sig[-train_values_sig,]\ntest_y_sig <- data.matrix(y[as.numeric(rownames(test_fea_sig)),])\n\n\ntrain_fea_sig <- data.matrix(train_fea_sig)\n\ntest_fea_sig <- data.matrix(test_fea_sig)\n\n#the training and test data is stored in matrix form\n```\n\n\n```{r}\n# From the class package, we use knn.cv to validate the exisitng response variables \n# kNN of order 5 is used\n\nfit_knn_sig <- knn.cv(train_fea_sig,train_y_sig,k= 5)\n\n# the output is used as the new response varible and is used to predict test values\n```\n\n\n\n```{r}\n# Using the testing set and the training data predictions are made \n\ncheck_test_sig <-data.frame(knn(train_fea_sig,test_fea_sig,fit_knn_sig, k= 5))\ncheck_test_sig$a <- test_y_sig\n\ncolnames(check_test_sig) <- c(\"Model output\",\"original data\")\n\n\ncheck_test_sig$`Model output`<-data.frame(check_test_sig$`Model output`)\n\nfor (i in 1:43)\n{\n  if(check_test_sig$`Model output`[i,] == check_test_sig$`original data`[i,])\n  {\n    check_test_sig$accuracy[i] <- 1\n  }\n  else\n  {\n    check_test_sig$accuracy[i] <- 0\n  }\n  i= i+1\n  \n}\n```\n**accuracy of the kNN model of order 5 is **\n```{r}\n(sum(check_test_sig$accuracy)/43)*100\n\n\n\n```\n\n\n\n```{r}\n\n#to compute the accuracy value for various levels of kNN\n# we must first initialise a storage data frame\n\naccuracy_test_4 <- data.frame(5:25)\n\n\nfor(j in 1:20)\n{\n  check_test_sig <-data.frame(knn(train_fea_sig,test_fea_sig,fit_knn_sig, k= j+4))\n  check_test_sig$a <- test_y\n\n  colnames(check_test_sig) <- c(\"Model output\",\"original data\")\n\n  check_test_sig$`Model output`<-data.frame(check_test_sig$`Model output`)\n\n  for (i in 1:43)\n    {\n      if(check_test_sig$`Model output`[i,] == check_test_sig$`original data`[i,])\n        {\n          check_test_sig$accuracy[i] <- 1\n        }\n      else\n        {\n          check_test_sig$accuracy[i] <- 0\n        }\n    i= i+1\n  \n    }\n\n  accuracy_test_4$k_value[j] <- j+4\n  accuracy_test_4$Accuracy[j] <- sum(check_test_sig$accuracy)/43\n  \n\n}\naccuracy_test_4 <- accuracy_test_4[-1] \naccuracy_test_4 <- accuracy_test_4[-21,] \n\n# the data frame accuracy_test_4 contains the accuracy values for a reasonable range of K values\n```\n\n\n```{r}\nplot(accuracy_test_4$k_value,accuracy_test_4$Accuracy, type = \"l\")\n```\n\nOptimal value for k is 12 or 14  \n\n\nBy analysing the test class we can calculate the testing accuracy\n```{r}\ntable(test_y_sig)\n```\nHere we can see that out of the 43 values there are 32 0's and 11 1's, hence to calculate null accuracy we get.  \n\nThus null accuracy is at\n```{r}\n (as.vector(table(test_y_sig))[1]/43)*100\n```\n\n\n",
    "created" : 1456805191082.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "807512759",
    "id" : "62ED2CCB",
    "lastKnownWriteTime" : 1456827966,
    "path" : "~/Homework 2/question2.Rmd",
    "project_path" : "question2.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "type" : "r_markdown"
}